import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
from src.utils import get_all_datasets, get_dataset
from src.models.llms import load_llm

st.set_page_config(page_title="üìÇ Chi Ti·∫øt B·ªô D·ªØ Li·ªáu", layout="wide")
st.title("üìÇ Chi Ti·∫øt B·ªô D·ªØ Li·ªáu")

llm = load_llm("gpt-3.5-turbo")

# ---------- H√†m h·ªó tr·ª£ ----------
def safe_read_csv(file_path):
    for enc in ['utf-8', 'ISO-8859-1', 'utf-16', 'cp1252']:
        try:
            return pd.read_csv(file_path, encoding=enc)
        except UnicodeDecodeError:
            continue
    raise UnicodeDecodeError("Kh√¥ng th·ªÉ gi·∫£i m√£ file v·ªõi c√°c encoding ph·ªï bi·∫øn.")

def analyze_column(col_name, series):
    info = {'name': col_name, 'dtype': str(series.dtype), 'missing_pct': series.isna().mean() * 100, 'unique': series.nunique()}
    if pd.api.types.is_numeric_dtype(series):
        desc = series.describe()
        info.update({
            'min': desc['min'], 'max': desc['max'], 'mean': desc['mean'],
            'median': series.median(), 'std': desc['std'],
            'outliers': ((series < (desc['25%'] - 1.5*(desc['75%'] - desc['25%']))) | (series > (desc['75%'] + 1.5*(desc['75%'] - desc['25%'])))).sum(),
            'type': 'Numeric'
        })
    elif series.nunique() == 2:
        info['type'] = 'Boolean'
    elif info['unique'] == len(series):
        info['type'] = 'ID'
    elif info['unique'] <= 20:
        info['type'] = 'Category'
    else:
        info['type'] = 'Text'
    return info

def guess_column_semantic_llm(col_name):
    prompt = f"Lo·∫°i ng·ªØ nghƒ©a ho·∫∑c √Ω nghƒ©a c·ªßa c·ªôt c√≥ t√™n '{col_name}' trong b·ªô d·ªØ li·ªáu l√† g√¨? Tr·∫£ l·ªùi b·∫±ng 3-5 t·ª´ ti·∫øng Vi·ªát."
    return llm.invoke(prompt)

@st.cache_data(show_spinner=False)
def get_cleaning_suggestions(col_stats):
    cols_description = "\n".join([
        f"C·ªôt: {col['name']} | Lo·∫°i: {col['dtype']} | Thi·∫øu: {col['missing_pct']:.2f}%" for col in col_stats
    ])
    prompt = f"""
D·ª±a tr√™n t√≥m t·∫Øt sau v·ªÅ c√°c c·ªôt trong b·ªô d·ªØ li·ªáu:
{cols_description}

H√£y ƒë·ªÅ xu·∫•t k·∫ø ho·∫°ch l√†m s·∫°ch v·ªõi c√°c quy t·∫Øc sau:
- Ch·ªâ x√≥a c√°c c·ªôt n·∫øu t·ª∑ l·ªá thi·∫øu > 50%.
- ƒê·ªëi v·ªõi c√°c c·ªôt c√≥ gi√° tr·ªã thi·∫øu ‚â§ 50%:
    - N·∫øu l√† s·ªë: ƒëi·ªÅn b·∫±ng trung v·ªã.
    - N·∫øu l√† ph√¢n lo·∫°i: ƒëi·ªÅn b·∫±ng mode.
- Ch·ªâ lo·∫°i b·ªè ngo·∫°i l·ªá t·ª´ c√°c c·ªôt c√≥ d·ªØ li·ªáu s·ªë kh√¥ng c√≥ gi√° tr·ªã thi·∫øu.
- Chu·∫©n h√≥a c√°c c·ªôt s·ªë ch·ªâ khi ch√∫ng kh√¥ng ƒë∆∞·ª£c ƒëi·ªÅn ho·∫∑c lo·∫°i b·ªè ngo·∫°i l·ªá, v√† gi√° tr·ªã t·ªëi ƒëa l·ªõn h∆°n nhi·ªÅu so v·ªõi 1.
- Kh√¥ng √°p d·ª•ng qu√° hai b∆∞·ªõc l√†m s·∫°ch tr√™n c√πng m·ªôt c·ªôt.
- Nh√≥m c√°c c·ªôt m·ªôt c√°ch logic v√† gi·∫£i th√≠ch ng·∫Øn g·ªçn trong nh·∫≠n x√©t.

Tr·∫£ v·ªÅ k·∫ø ho·∫°ch d∆∞·ªõi d·∫°ng danh s√°ch d·∫•u ƒë·∫ßu d√≤ng r√µ r√†ng.
"""
    return llm.invoke(prompt)

@st.cache_data(show_spinner=False)
def refine_cleaning_strategy(user_input, base_plan):
    prompt = f"""
K·∫ø ho·∫°ch l√†m s·∫°ch hi·ªán t·∫°i:
{base_plan}

Ng∆∞·ªùi d√πng mu·ªën: {user_input}

C·∫≠p nh·∫≠t k·∫ø ho·∫°ch l√†m s·∫°ch ph√π h·ª£p.
"""
    return llm.invoke(prompt)

@st.cache_data(show_spinner=False)
def generate_cleaning_code_from_plan(plan):
    prompt = f"""
Chuy·ªÉn ƒë·ªïi k·∫ø ho·∫°ch l√†m s·∫°ch sau th√†nh m√£ Python h·ª£p l·ªá s·ª≠ d·ª•ng pandas.
Ch·ªâ tr·∫£ v·ªÅ m√£ Python c√≥ th·ªÉ th·ª±c thi tr·ª±c ti·∫øp trong Python.
Gi·∫£ ƒë·ªãnh dataframe ƒë∆∞·ª£c ƒë·∫∑t t√™n l√† `df`.

Tr∆∞·ªõc khi √°p d·ª•ng c√°c ph∆∞∆°ng th·ª©c `.str` (v√≠ d·ª• `.str.replace`), lu√¥n ki·ªÉm tra dtype c·ªßa c·ªôt nh∆∞ th·∫ø n√†y:
if df["t√™n_c·ªôt"].dtype == "object":
    df["t√™n_c·ªôt"] = df["t√™n_c·ªôt"].str.replace(",", "").astype(float)

C≈©ng ƒë·∫£m b·∫£o r·∫±ng b·∫•t k·ª≥ chu·ªói n√†o nh∆∞ '1,000' ho·∫∑c '2,500.50' ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi th√†nh gi√° tr·ªã s·ªë tr∆∞·ªõc khi l√†m s·∫°ch th√™m.

K·∫ø ho·∫°ch L√†m s·∫°ch:
{plan}
"""
    return llm.invoke(prompt)

def extract_valid_code(llm_response):
    match = re.search(r"```(?:python)?\n(.*?)```", llm_response.strip(), re.DOTALL)
    if match:
        return match.group(1)
    lines = llm_response.splitlines()
    code_lines = [line for line in lines if line.strip() and not line.strip().startswith("#")]
    return "\n".join(code_lines)

def generate_insight(info):
    if info['type'] == 'ID':
        return "üîπ ƒê√¢y l√† c·ªôt ƒë·ªãnh danh duy nh·∫•t."
    if info['missing_pct'] > 0:
        return f"‚ö†Ô∏è {info['missing_pct']:.1f}% gi√° tr·ªã thi·∫øu."
    if 'std' in info and info['std'] < 1e-3:
        return "‚ö†Ô∏è ƒê·ªô bi·∫øn thi√™n r·∫•t th·∫•p."
    if info['unique'] < 5 and info['type'] == 'Category':
        return "‚ÑπÔ∏è Ph√¢n lo·∫°i v·ªõi <5 gi√° tr·ªã ri√™ng bi·ªát."
    return "‚úÖ Kh√¥ng ph√°t hi·ªán v·∫•n ƒë·ªÅ l·ªõn."

def plot_distribution(col_name, series):
    fig, ax = plt.subplots()
    if pd.api.types.is_numeric_dtype(series):
        ax.hist(series.dropna(), bins=20, color='#69b3a2')
        ax.set_xlabel(col_name)
        ax.set_ylabel('T·∫ßn su·∫•t')
    else:
        vc = series.fillna("NaN").value_counts().head(20)
        ax.bar(vc.index.astype(str), vc.values, color='#8c54ff')
        ax.set_xticks(range(len(vc.index)))  # S·ª≠a warning
        ax.set_xticklabels(vc.index, rotation=45, ha='right')
        ax.set_ylabel('S·ªë l∆∞·ª£ng')
    ax.set_title(f"Ph√¢n ph·ªëi: {col_name}")
    st.pyplot(fig)

def fix_numeric_strings(df):
    for col in df.select_dtypes(include='object').columns:
        if df[col].dropna().apply(lambda x: isinstance(x, str)).all():
            try:
                df[col] = df[col].str.replace(',', '', regex=False)
                df[col] = pd.to_numeric(df[col], errors='coerce')
            except Exception as e:
                print(f"Kh√¥ng th·ªÉ l√†m s·∫°ch c·ªôt {col}: {e}")
    return df

def show_skew_kurtosis(df, cleaned_df):
    raw_cols = df.select_dtypes(include='number').columns
    clean_cols = cleaned_df.select_dtypes(include='number').columns
    numeric_cols = list(set(raw_cols).intersection(set(clean_cols)))

    if not numeric_cols:
        st.info("Kh√¥ng c√≥ c·ªôt s·ªë chung n√†o kh·∫£ d·ª•ng cho b√°o c√°o ƒë·ªô l·ªách/ƒë·ªô nh·ªçn.")
        return

    report = pd.DataFrame(index=numeric_cols)
    report['ƒê·ªô l·ªách (Tr∆∞·ªõc)'] = df[numeric_cols].skew()
    report['ƒê·ªô nh·ªçn (Tr∆∞·ªõc)'] = df[numeric_cols].kurtosis()
    report['ƒê·ªô l·ªách (Sau)'] = cleaned_df[numeric_cols].skew()
    report['ƒê·ªô nh·ªçn (Sau)'] = cleaned_df[numeric_cols].kurtosis()
    st.dataframe(report.round(2), use_container_width=True)

    st.markdown("### üìä Tr·ª±c quan h√≥a")

    fig1, ax1 = plt.subplots()
    report[['ƒê·ªô l·ªách (Tr∆∞·ªõc)', 'ƒê·ªô l·ªách (Sau)']].plot(kind='bar', ax=ax1)
    ax1.set_title('ƒê·ªô l·ªách Tr∆∞·ªõc vs Sau L√†m s·∫°ch')
    ax1.set_ylabel('ƒê·ªô l·ªách')
    ax1.set_xlabel('ƒê·∫∑c tr∆∞ng')
    ax1.set_xticks(range(len(numeric_cols)))
    ax1.set_xticklabels(numeric_cols, rotation=45, ha='right')
    ax1.legend()
    st.pyplot(fig1)

    try:
        insight1 = llm.invoke(f"""
H√£y gi·∫£i th√≠ch bi·ªÉu ƒë·ªì thanh ƒë·ªô l·ªách n√†y so s√°nh tr∆∞·ªõc vs sau l√†m s·∫°ch:
{report[['ƒê·ªô l·ªách (Tr∆∞·ªõc)', 'ƒê·ªô l·ªách (Sau)']].to_markdown()}
""")
        st.markdown("#### ü§ñ Nh·∫≠n x√©t v·ªÅ ƒê·ªô l·ªách")
        st.info(insight1)
    except Exception:
        st.warning("Kh√¥ng th·ªÉ gi·∫£i th√≠ch bi·ªÉu ƒë·ªì ƒë·ªô l·ªách qua LLM.")

    fig2, ax2 = plt.subplots()
    report[['ƒê·ªô nh·ªçn (Tr∆∞·ªõc)', 'ƒê·ªô nh·ªçn (Sau)']].plot(kind='bar', ax=ax2)
    ax2.set_title('ƒê·ªô nh·ªçn Tr∆∞·ªõc vs Sau L√†m s·∫°ch')
    ax2.set_ylabel('ƒê·ªô nh·ªçn')
    ax2.set_xlabel('ƒê·∫∑c tr∆∞ng')
    ax2.set_xticks(range(len(numeric_cols)))
    ax2.set_xticklabels(numeric_cols, rotation=45, ha='right')
    ax2.legend()
    st.pyplot(fig2)

    try:
        insight2 = llm.invoke(f"""
H√£y gi·∫£i th√≠ch bi·ªÉu ƒë·ªì thanh ƒë·ªô nh·ªçn n√†y so s√°nh tr∆∞·ªõc vs sau l√†m s·∫°ch:
{report[['ƒê·ªô nh·ªçn (Tr∆∞·ªõc)', 'ƒê·ªô nh·ªçn (Sau)']].to_markdown()}
""")
        st.markdown("#### ü§ñ Nh·∫≠n x√©t v·ªÅ ƒê·ªô nh·ªçn")
        st.info(insight2)
    except Exception:
        st.warning("Kh√¥ng th·ªÉ gi·∫£i th√≠ch bi·ªÉu ƒë·ªì ƒë·ªô nh·ªçn qua LLM.")

    try:
        interpretation = llm.invoke(f"""
H√£y ph√¢n t√≠ch nh·ªØng ƒëi·ªÅu sau:
1. B·∫£ng ƒë·ªô l·ªách v√† ƒë·ªô nh·ªçn d∆∞·ªõi ƒë√¢y.
2. C√°c bi·ªÉu ƒë·ªì thanh so s√°nh tr∆∞·ªõc vs sau l√†m s·∫°ch.

Sau ƒë√≥ cung c·∫•p:
- Gi·∫£i th√≠ch v·ªÅ c√°ch l√†m s·∫°ch ·∫£nh h∆∞·ªüng ƒë·∫øn t√≠nh ƒë·ªëi x·ª©ng ph√¢n ph·ªëi v√† h√†nh vi c·ªßa ƒëu√¥i.
- ƒê√°nh gi√° li·ªáu d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch c√≥ ph√π h·ª£p h∆°n cho ph√¢n t√≠ch th·ªëng k√™ hay kh√¥ng.
- ƒê·ªÅ xu·∫•t c√°c b∆∞·ªõc ti·∫øp theo n·∫øu v·∫´n c·∫ßn c·∫£i thi·ªán.

T√≥m t·∫Øt d·ªØ li·ªáu:
{report.to_markdown()}
""")
        st.markdown("### üìò Gi·∫£i th√≠ch b·ªüi LLM")
        st.write(interpretation)
    except Exception:
        st.warning("Kh√¥ng th·ªÉ gi·∫£i th√≠ch b√°o c√°o qua LLM.")




# T·∫£i B·ªô d·ªØ li·ªáu v√† Hi·ªÉn th·ªã Tabs
datasets = get_all_datasets()
if datasets:
    selected = st.selectbox("Ch·ªçn b·ªô d·ªØ li·ªáu:", [f"{d[0]} - {d[1]}" for d in datasets])
    dataset_id = int(selected.split(" - ")[0])
    dataset = get_dataset(dataset_id)
    df = safe_read_csv(dataset[2])
    st.markdown(f"### B·ªô d·ªØ li·ªáu: `{dataset[1]}` ‚Äî {df.shape[0]} h√†ng √ó {df.shape[1]} c·ªôt")

    tab1, tab2, tab3 = st.tabs(["üìä T·ªïng quan", "üßº L√†m s·∫°ch", "üìà ƒê·ªô l·ªách & ƒê·ªô nh·ªçn"])

    with tab1:
        for col in df.columns:
            with st.container():
                stats = analyze_column(col, df[col])
                st.markdown(f"#### üìå {col}")
                cols = st.columns([2, 3])
                with cols[0]:
                    st.markdown(f"**Lo·∫°i:** `{stats['type']}`")
                    if 'min' in stats:
                        st.markdown(f"- T·ªëi thi·ªÉu: `{stats['min']}`")
                        st.markdown(f"- T·ªëi ƒëa: `{stats['max']}`")
                        st.markdown(f"- Trung b√¨nh: `{stats['mean']:.2f}`")
                        st.markdown(f"- Trung v·ªã: `{stats['median']}`")
                        st.markdown(f"- ƒê·ªô l·ªách chu·∫©n: `{stats['std']:.2f}`")
                        st.markdown(f"- Ngo·∫°i l·ªá: `{stats['outliers']}`")
                    st.markdown(f"- Duy nh·∫•t: `{stats['unique']}`")
                    st.markdown(f"- Thi·∫øu: `{stats['missing_pct']:.2f}%`")
                    st.info(generate_insight(stats))
                with cols[1]:
                    plot_distribution(col, df[col])
            st.markdown("---")

    with tab2:
        col_stats = [dict(analyze_column(col, df[col]), semantic=guess_column_semantic_llm(col)) for col in df.columns]
        summary_df = pd.DataFrame([{**c, 'Thi·∫øu %': f"{c['missing_pct']:.2f}"} for c in col_stats])
        st.session_state.col_stats = col_stats
        st.session_state.summary_df = summary_df

        st.dataframe(summary_df[['name', 'dtype', 'semantic', 'type', 'unique', 'Thi·∫øu %']])
        base_plan = get_cleaning_suggestions(col_stats)
        st.session_state.base_cleaning_plan = base_plan
        st.markdown("### üßº K·∫ø ho·∫°ch L√†m s·∫°ch")
        st.markdown(base_plan)

        if st.toggle("üõ† T√πy ch·ªânh K·∫ø ho·∫°ch L√†m s·∫°ch"):
            user_input = st.text_input("‚úçÔ∏è S·ª≠a ƒë·ªïi k·∫ø ho·∫°ch l√†m s·∫°ch:")
            if user_input:
                st.session_state.base_cleaning_plan = refine_cleaning_strategy(user_input, base_plan)
                st.rerun()

        code_raw = generate_cleaning_code_from_plan(st.session_state.base_cleaning_plan)
        code_clean = extract_valid_code(code_raw)
        st.session_state.code_clean = code_clean
        with st.expander("üß™ M√£ L√†m s·∫°ch Th√¥ (debug)"):
            st.code(code_raw, language="markdown")

        try:
            exec_globals = {'df': df.copy(), 'pd': pd, 'np': np, 'fix_numeric_strings': fix_numeric_strings}
            exec("df = fix_numeric_strings(df)\n" + code_clean, exec_globals)
            cleaned_df = exec_globals['df']

            # Ch·ªâ khi kh√¥ng l·ªói m·ªõi g√°n v√†o session_state
            st.session_state.cleaned_df = cleaned_df
            st.session_state.raw_df = df

            st.markdown("### ‚úÖ Xem tr∆∞·ªõc D·ªØ li·ªáu ƒê√£ l√†m s·∫°ch")
            st.dataframe(cleaned_df.head())

        except Exception as e:
            st.error(f"L·ªói khi th·ª±c thi m√£ l√†m s·∫°ch: {e}")
            st.code(code_clean, language="python")

        if 'cleaned_df' in st.session_state:
            st.download_button(
                label="üßπ L√†m s·∫°ch & Xu·∫•t",
                data=st.session_state.cleaned_df.to_csv(index=False).encode('utf-8'),
                file_name="cleaned_dataset.csv",
                mime="text/csv"
            )

            with st.expander("üßæ M√£ Python ƒê√£ s·ª≠ d·ª•ng"):
                st.code(code_clean, language="python")




    with tab3:
        st.markdown("### üìà B√°o c√°o ƒê·ªô l·ªách & ƒê·ªô nh·ªçn")
        if "cleaned_df" in st.session_state and "raw_df" in st.session_state:
            show_skew_kurtosis(st.session_state.raw_df, st.session_state.cleaned_df)
        else:
            st.info("Vui l√≤ng ch·∫°y l√†m s·∫°ch trong tab 'üßº L√†m s·∫°ch' tr∆∞·ªõc.")
else:
    st.warning("Kh√¥ng t√¨m th·∫•y b·ªô d·ªØ li·ªáu n√†o. Vui l√≤ng t·∫£i l√™n m·ªôt b·ªô d·ªØ li·ªáu trong B·∫£ng ƒëi·ªÅu khi·ªÉn.")
