import streamlit as st
import pandas as pd
import os
from datetime import datetime
from src.utils import init_db, add_dataset, get_all_datasets, delete_dataset, rename_dataset, safe_read_csv

# Import UI components
from src.components.ui_components import (
    render_professional_header, render_metric_cards, render_feature_card,
    render_insight_card, create_data_quality_indicator, PROFESSIONAL_CSS
)

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import time

st.set_page_config(page_title="Báº£ng Ä‘iá»u khiá»ƒn ChuyÃªn nghiá»‡p", layout="wide", page_icon="ğŸ“Š")

# Apply professional styling
st.markdown(PROFESSIONAL_CSS, unsafe_allow_html=True)

# Professional header
render_professional_header(
    "Báº£ng Ä‘iá»u khiá»ƒn PhÃ¢n tÃ­ch Äa Bá»™ dá»¯ liá»‡u",
    "Táº£i lÃªn, quáº£n lÃ½ vÃ  khÃ¡m phÃ¡ má»‘i quan há»‡ giá»¯a dá»¯ liá»‡u cá»§a báº¡n vá»›i thÃ´ng tin chi tiáº¿t Ä‘Æ°á»£c há»— trá»£ bá»Ÿi AI",
    "ğŸ“Š"
)

init_db()
if not os.path.exists('data/uploads'):
    os.makedirs('data/uploads')

def show_loading_animation(text="Äang xá»­ lÃ½..."):
    """Show loading animation"""
    return st.markdown(f"""
    <div style="display: flex; align-items: center; justify-content: center; padding: 2rem; background: #f8f9fa; border-radius: 10px; margin: 1rem 0;">
        <div style="border: 4px solid #f3f3f3; border-top: 4px solid #667eea; border-radius: 50%; width: 40px; height: 40px; animation: spin 1s linear infinite; margin-right: 1rem;"></div>
        <span style="color: #667eea; font-weight: 500;">{text}</span>
    </div>
    <style>
        @keyframes spin {{
            0% {{ transform: rotate(0deg); }}
            100% {{ transform: rotate(360deg); }}
        }}
    </style>
    """, unsafe_allow_html=True)

def create_enhanced_analytics_dashboard(datasets):
    """Create a beautiful dark theme professional analytics dashboard"""
    try:
        # Validate input data
        if not datasets or len(datasets) == 0:
            return create_empty_dashboard_placeholder()

        # Prepare data with enhanced validation
        dataset_info = []
        for d in datasets:
            try:
                if len(d) >= 5:
                    name = str(d[1])[:15] + "..." if len(str(d[1])) > 15 else str(d[1])
                    rows = max(0, int(d[2]) if d[2] is not None else 0)
                    cols = max(1, int(d[3]) if d[3] is not None else 1)
                    
                    try:
                        upload_date = datetime.strptime(str(d[4]), "%Y-%m-%d %H:%M:%S")
                    except:
                        upload_date = datetime.now()
                    
                    dataset_info.append({
                        'name': name,
                        'rows': rows,
                        'cols': cols,
                        'date': upload_date.date(),
                        'density': rows / cols if cols > 0 else 0,
                        'size_category': get_size_category(rows)
                    })
            except Exception:
                continue

        if not dataset_info:
            return create_empty_dashboard_placeholder()

        # Create beautiful subplot layout
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                'ğŸ“Š Dataset Size Overview', 
                'ğŸ“ˆ Upload Timeline', 
                'ğŸ”¢ Column Distribution', 
                'ğŸ’ Data Density Analysis'
            ],
            vertical_spacing=0.15,
            horizontal_spacing=0.12
        )
        
        # Dark theme color palette - vibrant colors that pop on dark background
        colors = {
            'primary': '#00d4ff',      # Bright cyan
            'secondary': '#ff6b9d',    # Pink
            'accent': '#c44569',       # Dark pink
            'success': '#00ff88',      # Bright green
            'warning': '#ffeb3b',      # Bright yellow
            'info': '#7c4dff',         # Purple
            'gradient': ['#00d4ff', '#ff6b9d', '#00ff88', '#ffeb3b', '#7c4dff', '#ff5722']
        }
        
        # Chart 1: Neon-style Dataset Sizes
        top_datasets = sorted(dataset_info, key=lambda x: x['rows'], reverse=True)[:8]
        names = [info['name'] for info in top_datasets]
        sizes = [info['rows'] for info in top_datasets]
        
        # Create gradient effect
        max_size = max(sizes) if sizes else 1
        bar_colors = []
        for size in sizes:
            intensity = size / max_size
            bar_colors.append(f'rgba(0, 212, 255, {0.3 + 0.7 * intensity})')
        
        fig.add_trace(
            go.Bar(
                x=names,
                y=sizes,
                marker=dict(
                    color=bar_colors,
                    line=dict(color=colors['primary'], width=2),
                    pattern=dict(shape="")
                ),
                text=[f"{size:,}" for size in sizes],
                textposition="outside",
                textfont=dict(color='white', size=11, family="Arial Bold"),
                name="Records",
                hovertemplate=(
                    "<b style='color:#00d4ff'>%{x}</b><br>"
                    "Records: <b>%{y:,}</b><br>"
                    "<extra></extra>"
                )
            ),
            row=1, col=1
        )
        
        # Chart 2: Glowing Timeline
        date_counts = {}
        for info in dataset_info:
            date_str = info['date'].strftime("%Y-%m-%d")
            date_counts[date_str] = date_counts.get(date_str, 0) + 1
        
        if date_counts:
            dates = sorted(date_counts.keys())
            daily_counts = [date_counts[date] for date in dates]
            
            # Calculate cumulative
            cumulative = []
            total = 0
            for count in daily_counts:
                total += count
                cumulative.append(total)
            
            # Main cumulative line with glow effect
            fig.add_trace(
                go.Scatter(
                    x=dates,
                    y=cumulative,
                    mode='lines+markers',
                    line=dict(
                        color=colors['secondary'], 
                        width=4,
                        shape='spline'
                    ),
                    marker=dict(
                        size=10, 
                        color=colors['primary'],
                        line=dict(color='white', width=2)
                    ),
                    fill='tonexty',
                    fillcolor='rgba(255, 107, 157, 0.2)',
                    name="Total Datasets",
                    hovertemplate=(
                        "<b>Date:</b> %{x}<br>"
                        "<b>Total:</b> %{y}<br>"
                        "<extra></extra>"
                    )
                ),
                row=1, col=2
            )
            
            # Add daily bars with glow
            fig.add_trace(
                go.Bar(
                    x=dates,
                    y=daily_counts,
                    marker=dict(
                        color='rgba(0, 255, 136, 0.4)',
                        line=dict(color=colors['success'], width=1)
                    ),
                    name="Daily",
                    opacity=0.6,
                    hovertemplate=(
                        "<b>Date:</b> %{x}<br>"
                        "<b>New uploads:</b> %{y}<br>"
                        "<extra></extra>"
                    )
                ),
                row=1, col=2
            )
        
        # Chart 3: Neon Column Distribution
        col_counts = [info['cols'] for info in dataset_info]
        if col_counts:
            fig.add_trace(
                go.Histogram(
                    x=col_counts,
                    marker=dict(
                        color='rgba(255, 235, 59, 0.7)',
                        line=dict(color=colors['warning'], width=2)
                    ),
                    name="Columns",
                    hovertemplate="Columns: %{x}<br>Count: %{y}<extra></extra>"
                ),
                row=2, col=1
            )
        
        # Chart 4: Glowing Density Bubbles
        densities = [info['density'] for info in dataset_info]
        bubble_sizes = [min(40, max(15, info['rows']/500)) for info in dataset_info]
        
        # Color mapping based on size category
        category_colors = {
            'Small': colors['success'],
            'Medium': colors['warning'], 
            'Large': colors['primary'],
            'Very Large': colors['secondary']
        }
        
        bubble_colors = [category_colors.get(info['size_category'], colors['primary']) for info in dataset_info]
        
        fig.add_trace(
            go.Scatter(
                x=list(range(len(dataset_info))),
                y=densities,
                mode='markers',
                marker=dict(
                    size=bubble_sizes,
                    color=bubble_colors,
                    opacity=0.8,
                    line=dict(color='white', width=2)
                ),
                text=[info['name'] for info in dataset_info],
                customdata=[info['size_category'] for info in dataset_info],
                name="Density",
                hovertemplate=(
                    "<b>%{text}</b><br>"
                    "Density: <b>%{y:.1f}</b><br>"
                    "Category: <b>%{customdata}</b><br>"
                    "<extra></extra>"
                )
            ),
            row=2, col=2
        )
        
        # Apply dark theme styling
        fig.update_layout(
            height=650,
            showlegend=False,
            title=dict(
                text="ğŸŒŸ VizGenie-GPT Analytics Dashboard",
                x=0.5,
                font=dict(size=22, color='#ffffff', family="Arial Black")
            ),
            font=dict(size=11, color='#e0e0e0'),
            # Dark theme colors
            plot_bgcolor='#1a1a1a',
            paper_bgcolor='#0d1117',
            margin=dict(t=80, l=60, r=60, b=60)
        )
        
        # Update subplot titles for dark theme
        for annotation in fig['layout']['annotations'][:4]:  # First 4 are subplot titles
            annotation.update(
                font=dict(size=13, color='#ffffff', family="Arial Bold"),
                bgcolor='rgba(255, 255, 255, 0.1)',
                bordercolor='rgba(0, 212, 255, 0.5)',
                borderwidth=1,
                borderpad=8
            )
        
        # Style axes for dark theme - safe approach
        # Apply to all subplots individually to avoid conflicts
        for row in [1, 2]:
            for col in [1, 2]:
                fig.update_xaxes(
                    gridcolor='rgba(255, 255, 255, 0.1)',
                    gridwidth=1,
                    showline=True,
                    linecolor='rgba(255, 255, 255, 0.3)',
                    linewidth=1,
                    tickfont_color='#e0e0e0',
                    row=row, col=col
                )
                fig.update_yaxes(
                    gridcolor='rgba(255, 255, 255, 0.1)',
                    gridwidth=1,
                    showline=True,
                    linecolor='rgba(255, 255, 255, 0.3)',
                    linewidth=1,
                    tickfont_color='#e0e0e0',
                    row=row, col=col
                )
        
        # Specific styling for each chart
        fig.update_xaxes(tickangle=-45, row=1, col=1)
        fig.update_yaxes(tickformat=',.0f', row=1, col=1)
        
        # Add subtle glow effect annotation
        fig.add_annotation(
            text="âœ¨ Professional Analytics Suite â€¢ Powered by AI",
            xref="paper", yref="paper",
            x=0.5, y=-0.05,
            showarrow=False,
            font=dict(size=10, color='rgba(255, 255, 255, 0.6)'),
            xanchor='center'
        )
        
        return fig
        
    except Exception as e:
        return create_error_dashboard(str(e))

def get_size_category(rows):
    """Categorize dataset size"""
    if rows < 1000:
        return "Small"
    elif rows < 10000:
        return "Medium"
    elif rows < 100000:
        return "Large"
    else:
        return "Very Large"

def create_empty_dashboard_placeholder():
    """Create beautiful dark empty state"""
    fig = go.Figure()
    
    fig.add_annotation(
        text=(
            "ğŸŒŸ Welcome to VizGenie-GPT Analytics<br><br>"
            "ğŸ“Š Upload your first dataset to unlock beautiful insights<br>"
            "ğŸ’¡ Professional dark-theme analytics powered by AI<br><br>"
            "<i style='color:#00d4ff'>Ready to illuminate your data!</i>"
        ),
        xref="paper", yref="paper",
        x=0.5, y=0.5,
        showarrow=False,
        font=dict(size=16, color='#ffffff'),
        bgcolor='rgba(0, 212, 255, 0.1)',
        bordercolor='rgba(0, 212, 255, 0.5)',
        borderwidth=2,
        borderpad=30,
        align='center'
    )
    
    fig.update_layout(
        height=500,
        title=dict(
            text="ğŸŒŸ VizGenie-GPT Analytics Dashboard",
            x=0.5,
            font=dict(size=22, color='#ffffff', family="Arial Black")
        ),
        plot_bgcolor='#1a1a1a',
        paper_bgcolor='#0d1117',
        xaxis=dict(visible=False),
        yaxis=dict(visible=False)
    )
    
    return fig

def create_error_dashboard(error_msg):
    """Create beautiful dark error state"""
    fig = go.Figure()
    
    fig.add_annotation(
        text=(
            f"âš ï¸ Dashboard Error<br><br>"
            f"Something went wrong while creating your analytics dashboard.<br>"
            f"<small style='color:#ff6b9d'>Error: {error_msg[:100]}...</small><br><br>"
            f"ğŸ’¡ Please try refreshing the page or contact support."
        ),
        xref="paper", yref="paper",
        x=0.5, y=0.5,
        showarrow=False,
        font=dict(size=14, color='#ff5722'),
        bgcolor='rgba(255, 87, 34, 0.1)',
        bordercolor='rgba(255, 87, 34, 0.5)',
        borderwidth=2,
        borderpad=20,
        align='center'
    )
    
    fig.update_layout(
        height=400,
        title="ğŸŒŸ Dashboard Error",
        plot_bgcolor='#1a1a1a',
        paper_bgcolor='#0d1117',
        xaxis=dict(visible=False),
        yaxis=dict(visible=False)
    )
    
    return fig

def perform_ai_deep_analysis(datasets):
    """Perform AI deep analysis with loading indicators and error handling"""
    try:
        # Loading indicator
        loading_placeholder = st.empty()
        loading_placeholder.markdown(show_loading_animation("ğŸ¤– AI Ä‘ang phÃ¢n tÃ­ch sÃ¢u dá»¯ liá»‡u cá»§a báº¡n..."))
        
        # Simulate AI processing time
        time.sleep(2)
        
        # Analyze datasets
        total_records = sum([d[2] for d in datasets])
        total_fields = sum([d[3] for d in datasets])
        avg_size = total_records / len(datasets) if datasets else 0
        largest_dataset = max(datasets, key=lambda x: x[2]) if datasets else None
        
        # Generate insights
        insights = []
        
        if len(datasets) >= 3:
            insights.append({
                "icon": "ğŸ¯",
                "title": "CÆ¡ sá»Ÿ Dá»¯ liá»‡u Phong phÃº",
                "description": f"Báº¡n cÃ³ {len(datasets)} bá»™ dá»¯ liá»‡u vá»›i tá»•ng cá»™ng {total_records:,} báº£n ghi. ÄÃ¢y lÃ  cÆ¡ sá»Ÿ tuyá»‡t vá»i cho phÃ¢n tÃ­ch Ä‘a chiá»u vÃ  khÃ¡m phÃ¡ má»‘i quan há»‡ chÃ©o.",
                "confidence": 0.9,
                "action": "Thá»­ phÃ¢n tÃ­ch chÃ©o dá»¯ liá»‡u"
            })
        
        if largest_dataset and largest_dataset[2] > 10000:
            insights.append({
                "icon": "ğŸ“ˆ",
                "title": "Tiá»m nÄƒng Big Data",
                "description": f"Bá»™ dá»¯ liá»‡u '{largest_dataset[1]}' cÃ³ {largest_dataset[2]:,} báº£n ghi. KÃ­ch thÆ°á»›c nÃ y ráº¥t phÃ¹ há»£p cho machine learning vÃ  phÃ¢n tÃ­ch xu hÆ°á»›ng phá»©c táº¡p.",
                "confidence": 0.85,
                "action": "Ãp dá»¥ng thuáº­t toÃ¡n ML"
            })
        
        if total_fields > 50:
            insights.append({
                "icon": "ğŸ”—",
                "title": "Dá»¯ liá»‡u Äa chiá»u",
                "description": f"Vá»›i {total_fields} trÆ°á»ng dá»¯ liá»‡u tá»•ng cá»™ng, báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n phÃ¢n tÃ­ch tÆ°Æ¡ng quan sÃ¢u vÃ  phÃ¡t hiá»‡n cÃ¡c má»‘i quan há»‡ áº©n giá»¯a cÃ¡c biáº¿n.",
                "confidence": 0.8,
                "action": "Táº¡o ma tráº­n tÆ°Æ¡ng quan"
            })
        
        # Data quality assessment
        quality_scores = []
        for dataset in datasets:
            try:
                df = safe_read_csv(dataset[2])
                missing_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100
                quality_score = max(0, 100 - missing_pct)
                quality_scores.append(quality_score)
            except:
                quality_scores.append(75)  # Default score if can't read
        
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 75
        
        if avg_quality > 85:
            insights.append({
                "icon": "âœ…",
                "title": "Cháº¥t lÆ°á»£ng Dá»¯ liá»‡u Cao",
                "description": f"Cháº¥t lÆ°á»£ng dá»¯ liá»‡u trung bÃ¬nh lÃ  {avg_quality:.1f}%. Dá»¯ liá»‡u sáº¡ch nÃ y sáºµn sÃ ng cho cÃ¡c phÃ¢n tÃ­ch nÃ¢ng cao vÃ  mÃ´ hÃ¬nh hÃ³a.",
                "confidence": 0.9,
                "action": "Báº¯t Ä‘áº§u phÃ¢n tÃ­ch nÃ¢ng cao"
            })
        elif avg_quality < 60:
            insights.append({
                "icon": "âš ï¸",
                "title": "Cáº§n LÃ m sáº¡ch Dá»¯ liá»‡u",
                "description": f"Cháº¥t lÆ°á»£ng dá»¯ liá»‡u trung bÃ¬nh chá»‰ {avg_quality:.1f}%. NÃªn lÃ m sáº¡ch dá»¯ liá»‡u trÆ°á»›c khi phÃ¢n tÃ­ch Ä‘á»ƒ cÃ³ káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n.",
                "confidence": 0.85,
                "action": "Äi Ä‘áº¿n Chi tiáº¿t Bá»™ dá»¯ liá»‡u"
            })
        
        # Time-based analysis
        recent_uploads = [d for d in datasets 
                         if (datetime.now() - datetime.strptime(d[4], "%Y-%m-%d %H:%M:%S")).days < 7]
        
        if recent_uploads:
            insights.append({
                "icon": "âš¡",
                "title": "Dá»¯ liá»‡u Má»›i",
                "description": f"{len(recent_uploads)} bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c táº£i lÃªn trong 7 ngÃ y qua. Dá»¯ liá»‡u má»›i thÆ°á»ng pháº£n Ã¡nh xu hÆ°á»›ng hiá»‡n táº¡i vÃ  cÃ³ giÃ¡ trá»‹ phÃ¢n tÃ­ch cao.",
                "confidence": 0.75,
                "action": "PhÃ¢n tÃ­ch xu hÆ°á»›ng má»›i nháº¥t"
            })
        
        # Clear loading
        loading_placeholder.empty()
        
        return insights, avg_quality
        
    except Exception as e:
        st.error(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch AI: {str(e)}")
        return [], 75

# Enhanced sidebar for dataset upload
with st.sidebar:
    st.markdown("""
    <div style="text-align: center; padding: 1rem 0; border-bottom: 1px solid #e1e5e9; margin-bottom: 1rem;">
        <h3 style="color: #667eea; margin: 0;">ğŸ“‚ Quáº£n lÃ½ Bá»™ dá»¯ liá»‡u</h3>
        <small style="color: #666;">Táº£i lÃªn & Tá»• chá»©c</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Enhanced multi-file upload with progress
    st.markdown("#### ğŸ“¤ Táº£i lÃªn Bá»™ dá»¯ liá»‡u")
    uploaded_files = st.file_uploader(
        "Chá»n cÃ¡c file CSV (há»— trá»£ nhiá»u file)", 
        type=["csv"], 
        accept_multiple_files=True,
        help="ğŸ’¡ Táº£i lÃªn nhiá»u bá»™ dá»¯ liá»‡u Ä‘á»ƒ khÃ¡m phÃ¡ má»‘i quan há»‡ chÃ©o dá»¯ liá»‡u"
    )
    
    # Upload processing with better feedback
    if uploaded_files:
        upload_progress = st.progress(0)
        upload_status = st.empty()
        success_count = 0
        
        for i, uploaded_file in enumerate(uploaded_files):
            cache_key = f"uploaded_{uploaded_file.name}_{uploaded_file.size}"
            
            if cache_key not in st.session_state:
                upload_status.text(f"ğŸ”„ Äang xá»­ lÃ½ {uploaded_file.name}...")
                
                try:
                    # Validate file
                    if uploaded_file.size > 50 * 1024 * 1024:  # 50MB limit
                        st.error(f"âŒ File {uploaded_file.name} quÃ¡ lá»›n (>50MB)")
                        continue
                    
                    # Process file
                    now = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"{now}_{uploaded_file.name}"
                    file_path = os.path.join('data', 'uploads', filename)
                    
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # Read and validate CSV
                    df = safe_read_csv(file_path)
                    
                    if df.empty:
                        st.error(f"âŒ File {uploaded_file.name} trá»‘ng")
                        os.remove(file_path)
                        continue
                    
                    rows, cols = df.shape
                    upload_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    
                    add_dataset(filename, file_path, rows, cols, upload_time)
                    
                    st.session_state[cache_key] = True
                    success_count += 1
                    
                    upload_status.success(f"âœ… {uploaded_file.name} ({rows:,} hÃ ng, {cols} cá»™t)")
                    
                except Exception as e:
                    st.error(f"âŒ Lá»—i xá»­ lÃ½ {uploaded_file.name}: {str(e)}")
                    
            else:
                success_count += 1
            
            upload_progress.progress((i + 1) / len(uploaded_files))
        
        if success_count == len(uploaded_files):
            upload_status.success(f"ğŸ‰ ÄÃ£ táº£i lÃªn thÃ nh cÃ´ng {success_count}/{len(uploaded_files)} file!")
            time.sleep(1)
            st.rerun()

# Load datasets
datasets = get_all_datasets()

if datasets:
    # Enhanced dashboard metrics
    st.markdown("### ğŸ“Š Tá»•ng quan Báº£ng Ä‘iá»u khiá»ƒn")
    
    # Calculate comprehensive metrics
    total_datasets = len(datasets)
    total_rows = sum([d[2] for d in datasets])
    total_cols = sum([d[3] for d in datasets])
    avg_size = total_rows / total_datasets if total_datasets > 0 else 0
    
    # Additional metrics
    largest_dataset = max(datasets, key=lambda x: x[2]) if datasets else None
    newest_dataset = max(datasets, key=lambda x: datetime.strptime(x[4], "%Y-%m-%d %H:%M:%S")) if datasets else None
    
    # Calculate storage size
    total_size_mb = 0
    for d in datasets:
        try:
            if os.path.exists(os.path.join("data", "uploads", d[1])):
                total_size_mb += os.path.getsize(os.path.join("data", "uploads", d[1])) / (1024 * 1024)
        except:
            continue
    
    # Professional metric cards with enhanced data
    metrics = [
        {
            "title": "Tá»•ng Bá»™ dá»¯ liá»‡u", 
            "value": f"{total_datasets}", 
            "delta": "+3 tuáº§n nÃ y" if total_datasets > 0 else None
        },
        {
            "title": "Tá»•ng Báº£n ghi", 
            "value": f"{total_rows:,}", 
            "delta": f"+{total_rows//10:,} gáº§n Ä‘Ã¢y" if total_rows > 0 else None
        },
        {
            "title": "TrÆ°á»ng Dá»¯ liá»‡u", 
            "value": f"{total_cols}", 
            "delta": None
        },
        {
            "title": "Dung lÆ°á»£ng", 
            "value": f"{total_size_mb:.1f}MB", 
            "delta": None
        }
    ]
    
    render_metric_cards(metrics)
    
    # Enhanced analytics dashboard with loading and error handling
    st.markdown("### ğŸ“ˆ Báº£ng Ä‘iá»u khiá»ƒn PhÃ¢n tÃ­ch")
    
    dashboard_container = st.container()
    
    with dashboard_container:
        try:
            # Show loading for dashboard creation
            with st.spinner("ğŸ“Š Äang táº¡o dashboard phÃ¢n tÃ­ch..."):
                fig = create_enhanced_analytics_dashboard(datasets)
            
            # Display dashboard
            st.plotly_chart(fig, use_container_width=True, key="main_dashboard")
            
        except Exception as e:
            st.error(f"âŒ KhÃ´ng thá»ƒ táº¡o dashboard: {str(e)}")
            st.info("ğŸ’¡ Vui lÃ²ng thá»­ táº£i láº¡i trang hoáº·c kiá»ƒm tra dá»¯ liá»‡u")
    
    # AI Deep Analysis with enhanced loading
    st.markdown("### ğŸ¤– PhÃ¢n tÃ­ch SÃ¢u AI")
    
    if st.button("ğŸš€ Báº¯t Ä‘áº§u PhÃ¢n tÃ­ch AI", type="primary"):
        ai_insights, data_quality = perform_ai_deep_analysis(datasets)
        
        if ai_insights:
            st.markdown("#### ğŸ’¡ Insights Ä‘Æ°á»£c AI PhÃ¡t hiá»‡n")
            
            # Display insights in an attractive grid
            cols = st.columns(2)
            for i, insight in enumerate(ai_insights):
                with cols[i % 2]:
                    confidence_color = "#28a745" if insight['confidence'] > 0.8 else "#ffc107" if insight['confidence'] > 0.6 else "#dc3545"
                    
                    st.markdown(f"""
                    <div style="
                        background: linear-gradient(135deg, {confidence_color}15 0%, {confidence_color}25 100%);
                        border: 1px solid {confidence_color}30;
                        padding: 1.5rem;
                        border-radius: 12px;
                        margin: 0.5rem 0;
                        position: relative;
                    ">
                        <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                            <span style="font-size: 1.5rem; margin-right: 0.5rem;">{insight['icon']}</span>
                            <h4 style="margin: 0; color: #2c3e50;">{insight['title']}</h4>
                            <span style="
                                background: {confidence_color};
                                color: white;
                                padding: 0.2rem 0.5rem;
                                border-radius: 10px;
                                font-size: 0.7rem;
                                margin-left: auto;
                            ">{insight['confidence']:.0%}</span>
                        </div>
                        <p style="margin: 0.5rem 0; color: #495057;">{insight['description']}</p>
                        <small style="color: {confidence_color}; font-weight: 500;">ğŸ’¡ {insight['action']}</small>
                    </div>
                    """, unsafe_allow_html=True)
            
            # Overall data quality indicator
            st.markdown("#### ğŸ“Š ÄÃ¡nh giÃ¡ Tá»•ng thá»ƒ")
            quality_color = "#28a745" if data_quality > 85 else "#ffc107" if data_quality > 60 else "#dc3545"
            quality_status = "Tuyá»‡t vá»i" if data_quality > 85 else "KhÃ¡ tá»‘t" if data_quality > 60 else "Cáº§n cáº£i thiá»‡n"
            
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, {quality_color}15 0%, {quality_color}25 100%);
                border: 2px solid {quality_color};
                padding: 1.5rem;
                border-radius: 12px;
                text-align: center;
                margin: 1rem 0;
            ">
                <h3 style="margin: 0; color: {quality_color};">Cháº¥t lÆ°á»£ng Dá»¯ liá»‡u: {quality_status}</h3>
                <div style="font-size: 2rem; font-weight: bold; color: {quality_color}; margin: 0.5rem 0;">
                    {data_quality:.1f}%
                </div>
                <p style="margin: 0; color: #495057;">
                    Dá»±a trÃªn phÃ¢n tÃ­ch tÃ­nh toÃ n váº¹n, tÃ­nh nháº¥t quÃ¡n vÃ  Ä‘á»™ Ä‘áº§y Ä‘á»§ cá»§a dá»¯ liá»‡u
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        else:
            st.info("ğŸ¤– KhÃ´ng thá»ƒ táº¡o insights AI. Vui lÃ²ng thá»­ láº¡i sau.")
    
    # Dataset management section (existing code continues...)
    st.markdown("### ğŸ—‚ï¸ Quáº£n lÃ½ Bá»™ dá»¯ liá»‡u")
    
    # Filter and search options
    col1, col2, col3 = st.columns(3)
    
    with col1:
        search_term = st.text_input("ğŸ” TÃ¬m kiáº¿m bá»™ dá»¯ liá»‡u:", placeholder="Lá»c theo tÃªn...")
    
    with col2:
        size_filter = st.selectbox("ğŸ“ Lá»c kÃ­ch thÆ°á»›c:", ["Táº¥t cáº£", "Nhá» (<1K)", "Trung bÃ¬nh (1K-10K)", "Lá»›n (>10K)"])
    
    with col3:
        sort_by = st.selectbox("ğŸ“Š Sáº¯p xáº¿p theo:", ["TÃªn", "NgÃ y Táº£i lÃªn", "KÃ­ch thÆ°á»›c", "Cá»™t"])
    
    # Apply filters
    filtered_datasets = datasets
    
    if search_term:
        filtered_datasets = [d for d in filtered_datasets if search_term.lower() in d[1].lower()]
    
    if size_filter != "Táº¥t cáº£":
        if size_filter == "Nhá» (<1K)":
            filtered_datasets = [d for d in filtered_datasets if d[2] < 1000]
        elif size_filter == "Trung bÃ¬nh (1K-10K)":
            filtered_datasets = [d for d in filtered_datasets if 1000 <= d[2] <= 10000]
        elif size_filter == "Lá»›n (>10K)":
            filtered_datasets = [d for d in filtered_datasets if d[2] > 10000]
    
    # Sort datasets
    if sort_by == "TÃªn":
        filtered_datasets.sort(key=lambda x: x[1])
    elif sort_by == "NgÃ y Táº£i lÃªn":
        filtered_datasets.sort(key=lambda x: datetime.strptime(x[4], "%Y-%m-%d %H:%M:%S"), reverse=True)
    elif sort_by == "KÃ­ch thÆ°á»›c":
        filtered_datasets.sort(key=lambda x: x[2], reverse=True)
    elif sort_by == "Cá»™t":
        filtered_datasets.sort(key=lambda x: x[3], reverse=True)
    
    # Display datasets with enhanced management
    for dataset in filtered_datasets:
        id_, name, rows, cols, uploaded, status = dataset
        
        with st.expander(f"ğŸ“ {name}", expanded=False):
            try:
                file_path = os.path.join("data", "uploads", name)
                preview_df = safe_read_csv(file_path)
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown("#### ğŸ“Š Xem trÆ°á»›c Bá»™ dá»¯ liá»‡u")
                    st.dataframe(preview_df.head(5), use_container_width=True)
                    
                    # Quick statistics
                    numeric_cols = preview_df.select_dtypes(include=['number']).columns
                    categorical_cols = preview_df.select_dtypes(include=['object']).columns
                    missing_values = preview_df.isnull().sum().sum()
                    
                    # Data quality for this dataset
                    quality_score = create_data_quality_indicator(preview_df)
                
                with col2:
                    st.markdown("#### ğŸ¯ Thá»‘ng kÃª Nhanh")
                    
                    dataset_metrics = [
                        {"title": "Cá»™t Sá»‘", "value": str(len(numeric_cols)), "delta": None},
                        {"title": "Cá»™t VÄƒn báº£n", "value": str(len(categorical_cols)), "delta": None},
                        {"title": "Thiáº¿u", "value": str(missing_values), "delta": None},
                        {"title": "Cháº¥t lÆ°á»£ng", "value": f"{quality_score:.0%}", "delta": None}
                    ]
                    
                    render_metric_cards(dataset_metrics)
                    
                    st.markdown("#### âš¡ HÃ nh Ä‘á»™ng Nhanh")
                    
                    action_col1, action_col2 = st.columns(2)
                    
                    with action_col1:
                        if st.button("ğŸ” PhÃ¢n tÃ­ch", key=f"analyze_{id_}", use_container_width=True):
                            st.session_state.selected_dataset_id = id_
                            st.switch_page("pages/3_ğŸ“‚_Chi_Tiet_Bo_Du_Lieu.py")
                        
                        if st.button("ğŸ’¬ TrÃ² chuyá»‡n", key=f"chat_{id_}", use_container_width=True):
                            st.session_state.selected_dataset_id = id_
                            st.switch_page("main.py")
                    
                    with action_col2:
                        if st.button("ğŸ“Š Biá»ƒu Ä‘á»“", key=f"chart_{id_}", use_container_width=True):
                            st.session_state.selected_dataset_id = id_
                            st.switch_page("pages/6_ğŸ“ˆ_Bieu_Do_Thong_Minh.py")
                        
                        if st.button("ğŸ“‹ BÃ¡o cÃ¡o", key=f"report_{id_}", use_container_width=True):
                            st.session_state.selected_dataset_id = id_
                            st.switch_page("pages/5_ğŸ“‹_Bao_Cao_EDA.py")
                
                # Management options
                st.markdown("#### âš™ï¸ TÃ¹y chá»n Quáº£n lÃ½")
                
                mgmt_col1, mgmt_col2, mgmt_col3 = st.columns(3)
                
                with mgmt_col1:
                    new_name = st.text_input(
                        "Äá»•i tÃªn bá»™ dá»¯ liá»‡u:", 
                        value=name, 
                        key=f"rename_input_{id_}",
                        help="Äáº·t tÃªn mÃ´ táº£ cho bá»™ dá»¯ liá»‡u cá»§a báº¡n"
                    )
                    
                    if st.button("âœ… Äá»•i tÃªn", key=f"rename_btn_{id_}"):
                        try:
                            rename_dataset(id_, new_name)
                            st.success("âœ… ÄÃ£ Ä‘á»•i tÃªn bá»™ dá»¯ liá»‡u!")
                            time.sleep(1)
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ Lá»—i khi Ä‘á»•i tÃªn: {str(e)}")
                
                with mgmt_col2:
                    if st.button("ğŸ“¥ Táº£i xuá»‘ng", key=f"download_{id_}", help="Táº£i xuá»‘ng bá»™ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½"):
                        try:
                            csv_data = preview_df.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“¥ Táº£i xuá»‘ng CSV",
                                data=csv_data,
                                file_name=f"{name.split('_', 1)[-1] if '_' in name else name}",
                                mime="text/csv",
                                key=f"download_btn_{id_}"
                            )
                        except Exception as e:
                            st.error(f"âŒ Lá»—i khi táº¡o file táº£i xuá»‘ng: {str(e)}")
                
                with mgmt_col3:
                    if st.button("ğŸ—‘ï¸ XÃ³a", key=f"del_{id_}", type="secondary", help="XÃ³a vÄ©nh viá»…n bá»™ dá»¯ liá»‡u nÃ y"):
                        if st.checkbox(f"XÃ¡c nháº­n xÃ³a {name}", key=f"confirm_{id_}"):
                            try:
                                delete_dataset(id_)
                                st.warning(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a bá»™ dá»¯ liá»‡u: {name}")
                                time.sleep(1)
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ Lá»—i khi xÃ³a: {str(e)}")
                
            except Exception as e:
                st.error(f"âŒ KhÃ´ng thá»ƒ táº£i bá»™ dá»¯ liá»‡u: {str(e)}")
                
                # Show basic management even if preview fails
                mgmt_col1, mgmt_col2 = st.columns(2)
                
                with mgmt_col1:
                    new_name = st.text_input("Äá»•i tÃªn:", value=name, key=f"rename_error_{id_}")
                    if st.button("âœ… Äá»•i tÃªn", key=f"rename_error_btn_{id_}"):
                        try:
                            rename_dataset(id_, new_name)
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ Lá»—i: {str(e)}")
                
                with mgmt_col2:
                    if st.button("ğŸ—‘ï¸ XÃ³a", key=f"del_error_{id_}", type="secondary"):
                        try:
                            delete_dataset(id_)
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ Lá»—i: {str(e)}")

else:
    # Welcome screen for new users
    st.markdown("### ğŸ‘‹ ChÃ o má»«ng Ä‘áº¿n vá»›i VizGenie-GPT ChuyÃªn nghiá»‡p!")
    
    # Feature showcase
    col1, col2, col3 = st.columns(3)
    
    with col1:
        render_feature_card(
            "ğŸ¤– PhÃ¢n tÃ­ch Ä‘Æ°á»£c Há»— trá»£ bá»Ÿi AI",
            "Äáº·t cÃ¢u há»i phá»©c táº¡p vá» dá»¯ liá»‡u cá»§a báº¡n báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  nháº­n Ä‘Æ°á»£c thÃ´ng tin thÃ´ng minh vá»›i trá»±c quan hÃ³a Ä‘áº¹p máº¯t.",
            "ğŸ¤–"
        )
    
    with col2:
        render_feature_card(
            "ğŸ”— KhÃ¡m phÃ¡ ChÃ©o Bá»™ dá»¯ liá»‡u",
            "Táº£i lÃªn nhiá»u bá»™ dá»¯ liá»‡u vÃ  khÃ¡m phÃ¡ má»‘i quan há»‡ áº©n vÃ  mÃ´ hÃ¬nh qua cÃ¡c nguá»“n dá»¯ liá»‡u cá»§a báº¡n.",
            "ğŸ”—"
        )
    
    with col3:
        render_feature_card(
            "ğŸ“Š Biá»ƒu Ä‘á»“ ChuyÃªn nghiá»‡p",
            "Táº¡o ra nhá»¯ng biá»ƒu Ä‘á»“ tuyá»‡t Ä‘áº¹p, sáºµn sÃ ng xuáº¥t báº£n vá»›i báº£ng mÃ u thÃ´ng minh vÃ  tÃ­nh nÄƒng tÆ°Æ¡ng tÃ¡c.",
            "ğŸ“Š"
        )
    
    # Getting started guide
    st.markdown("### ğŸš€ Báº¯t Ä‘áº§u")
    
    render_insight_card("""
    **ğŸ“‹ HÆ°á»›ng dáº«n Nhanh:**
    
    1. **ğŸ“¤ Táº£i lÃªn Dá»¯ liá»‡u**: Sá»­ dá»¥ng thanh bÃªn Ä‘á»ƒ táº£i lÃªn má»™t hoáº·c nhiá»u file CSV
    2. **ğŸ¤– Äáº·t CÃ¢u há»i**: TrÃ² chuyá»‡n vá»›i dá»¯ liá»‡u cá»§a báº¡n báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn
    3. **ğŸ“Š Táº¡o Trá»±c quan hÃ³a**: Táº¡o biá»ƒu Ä‘á»“ chuyÃªn nghiá»‡p tá»± Ä‘á»™ng
    4. **ğŸ”— TÃ¬m Má»‘i quan há»‡**: KhÃ¡m phÃ¡ mÃ´ hÃ¬nh qua nhiá»u bá»™ dá»¯ liá»‡u
    5. **ğŸ“„ Xuáº¥t BÃ¡o cÃ¡o**: Táº¡o bÃ¡o cÃ¡o PDF toÃ n diá»‡n cho cÃ¡c bÃªn liÃªn quan
    
    **ğŸ’¡ Máº¹o ChuyÃªn nghiá»‡p:**
    - Táº£i lÃªn cÃ¡c bá»™ dá»¯ liá»‡u liÃªn quan cÃ¹ng nhau Ä‘á»ƒ phÃ¢n tÃ­ch chÃ©o tá»‘t hÆ¡n
    - Sá»­ dá»¥ng tÃªn mÃ´ táº£ cho bá»™ dá»¯ liá»‡u cá»§a báº¡n
    - Äáº·t cÃ¢u há»i cá»¥ thá»ƒ Ä‘á»ƒ cÃ³ pháº£n há»“i AI tá»‘t hÆ¡n
    - Thá»­ cÃ¡c loáº¡i biá»ƒu Ä‘á»“ vÃ  báº£ng mÃ u khÃ¡c nhau
    """)
    
    # Sample data offer
    st.markdown("### ğŸ“š Thá»­ vá»›i Dá»¯ liá»‡u Máº«u")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š Táº£i Dá»¯ liá»‡u BÃ¡n hÃ ng Máº«u", type="primary", use_container_width=True):
            # Create sample sales dataset
            np.random.seed(42)
            sample_sales = pd.DataFrame({
                'date': pd.date_range('2023-01-01', periods=365, freq='D'),
                'revenue': np.random.normal(10000, 2000, 365),
                'customers': np.random.poisson(50, 365),
                'region': np.random.choice(['North', 'South', 'East', 'West'], 365),
                'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home'], 365)
            })
            
            # Save sample data
            sample_path = os.path.join('data', 'uploads', 'sample_sales_data.csv')
            sample_sales.to_csv(sample_path, index=False)
            
            # Add to database
            upload_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            add_dataset('sample_sales_data.csv', sample_path, len(sample_sales), len(sample_sales.columns), upload_time)
            
            st.success("âœ… ÄÃ£ táº£i dá»¯ liá»‡u bÃ¡n hÃ ng máº«u!")
            st.rerun()
    
    with col2:
        if st.button("ğŸ‘¥ Táº£i Dá»¯ liá»‡u KhÃ¡ch hÃ ng Máº«u", type="secondary", use_container_width=True):
            # Create sample customer dataset
            np.random.seed(24)
            sample_customers = pd.DataFrame({
                'customer_id': range(1, 501),
                'age': np.random.randint(18, 70, 500),
                'gender': np.random.choice(['Male', 'Female'], 500),
                'income': np.random.normal(50000, 15000, 500),
                'satisfaction_score': np.random.randint(1, 11, 500),
                'region': np.random.choice(['North', 'South', 'East', 'West'], 500)
            })
            
            # Save sample data
            sample_path = os.path.join('data', 'uploads', 'sample_customer_data.csv')
            sample_customers.to_csv(sample_path, index=False)
            
            # Add to database
            upload_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            add_dataset('sample_customer_data.csv', sample_path, len(sample_customers), len(sample_customers.columns), upload_time)
            
            st.success("âœ… ÄÃ£ táº£i dá»¯ liá»‡u khÃ¡ch hÃ ng máº«u!")
            st.rerun()

# Enhanced sidebar with navigation and tips
with st.sidebar:
    if datasets:
        st.markdown("---")
        st.markdown("### ğŸ¯ Thá»‘ng kÃª Nhanh")
        
        # Overall statistics
        try:
            total_size_mb = 0
            for d in datasets:
                try:
                    file_path = os.path.join("data", "uploads", d[1])
                    if os.path.exists(file_path):
                        total_size_mb += os.path.getsize(file_path) / (1024 * 1024)
                except:
                    continue
        except:
            total_size_mb = 0
        
        quick_stats = [
            {"title": "Bá»™ dá»¯ liá»‡u", "value": str(len(datasets)), "delta": None},
            {"title": "Tá»•ng KÃ­ch thÆ°á»›c", "value": f"{total_size_mb:.1f}MB", "delta": None},
            {"title": "Lá»›n nháº¥t", "value": f"{max(d[2] for d in datasets):,}" if datasets else "0", "delta": None}
        ]
        
        render_metric_cards(quick_stats)
    
    st.markdown("---")
    st.markdown("### ğŸ”— Äiá»u hÆ°á»›ng")
    
    nav_links = [
        ("ğŸ’¬ TrÃ² chuyá»‡n AI", "main.py"),
        ("ğŸ“Š Chi tiáº¿t Bá»™ dá»¯ liá»‡u", "pages/3_ğŸ“‚_Chi_Tiet_Bo_Du_Lieu.py"),
        ("ğŸ“ˆ Biá»ƒu Ä‘á»“ ThÃ´ng minh", "pages/6_ğŸ“ˆ_Bieu_Do_Thong_Minh.py"),
        ("ğŸ”— PhÃ¢n tÃ­ch ChÃ©o", "pages/7_ğŸ”—_Phan_Tich_Cheo_Du_Lieu.py"),
        ("ğŸ“‹ Lá»‹ch sá»­ Biá»ƒu Ä‘á»“", "pages/4_ğŸ“Š_Lich_Su_Bieu_Do.py"),
        ("ğŸ“„ BÃ¡o cÃ¡o EDA", "pages/5_ğŸ“‹_Bao_Cao_EDA.py"),
        ("ğŸ“– Vá» dá»± Ã¡n", "pages/ğŸ“–_Ve_Du_An.py")
    ]
    
    for label, page in nav_links:
        if st.button(label, key=f"nav_{label}", use_container_width=True):
            st.switch_page(page)
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ Máº¹o & Thá»§ thuáº­t")
    
    tips = [
        "ğŸ¯ **PhÃ¢n tÃ­ch Tá»‘t hÆ¡n**: Táº£i lÃªn cÃ¡c bá»™ dá»¯ liá»‡u liÃªn quan cÃ¹ng nhau",
        "ğŸ¨ **Háº¥p dáº«n Trá»±c quan**: Thá»­ cÃ¡c báº£ng mÃ u khÃ¡c nhau trong biá»ƒu Ä‘á»“", 
        "ğŸ¤– **CÃ¢u há»i ThÃ´ng minh**: Cá»¥ thá»ƒ vá» nhá»¯ng gÃ¬ báº¡n muá»‘n khÃ¡m phÃ¡",
        "ğŸ“Š **PhÃ¢n tÃ­ch ChÃ©o**: TÃ¬m kiáº¿m mÃ´ hÃ¬nh qua cÃ¡c bá»™ dá»¯ liá»‡u",
        "ğŸ“‹ **LÆ°u CÃ´ng viá»‡c**: Sá»­ dá»¥ng lá»‹ch sá»­ biá»ƒu Ä‘á»“ vÃ  quáº£n lÃ½ phiÃªn"
    ]
    
    for tip in tips:
        st.markdown(f"- {tip}")

# Footer with system info
st.markdown("---")
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**ğŸ§  VizGenie-GPT ChuyÃªn nghiá»‡p**")
    st.caption("Ná»n táº£ng PhÃ¢n tÃ­ch Äa Bá»™ dá»¯ liá»‡u NÃ¢ng cao")

with col2:
    if datasets:
        st.markdown(f"**ğŸ“Š Tráº¡ng thÃ¡i Há»‡ thá»‘ng**")
        st.caption(f"{len(datasets)} bá»™ dá»¯ liá»‡u â€¢ {sum(d[2] for d in datasets):,} tá»•ng báº£n ghi")
    else:
        st.markdown("**ğŸš€ Sáºµn sÃ ng Báº¯t Ä‘áº§u**")
        st.caption("Táº£i lÃªn bá»™ dá»¯ liá»‡u Ä‘áº§u tiÃªn Ä‘á»ƒ báº¯t Ä‘áº§u")

with col3:
    st.markdown("**ğŸ‘¨â€ğŸ’» Delay Group**")
    st.caption("LÃ m cho phÃ¢n tÃ­ch dá»¯ liá»‡u cÃ³ thá»ƒ tiáº¿p cáº­n vá»›i má»i ngÆ°á»i")