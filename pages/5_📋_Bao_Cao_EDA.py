import streamlit as st
import pandas as pd
import os
from src.utils import export_eda_report_to_pdf, init_db, get_all_datasets, rename_dataset, safe_read_csv
import matplotlib.pyplot as plt
import seaborn as sns
import json
import textwrap
import re

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

st.set_page_config(page_title="B√°o c√°o EDA", layout="wide")
st.title("üß† B√°o c√°o Ph√¢n t√≠ch Kh√°m ph√° D·ªØ li·ªáu (EDA)")

# LangChain LLM setup
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

def clean_and_fix_json(raw_response):
    """
    L√†m s·∫°ch v√† s·ª≠a l·ªói JSON t·ª´ LLM response m·ªôt c√°ch m·∫°nh m·∫Ω
    """
    try:
        # Lo·∫°i b·ªè markdown code blocks
        cleaned = re.sub(r"^```(?:json)?", "", raw_response.strip(), flags=re.IGNORECASE | re.MULTILINE)
        cleaned = re.sub(r"```$", "", cleaned.strip(), flags=re.MULTILINE)
        cleaned = cleaned.strip()
        
        # Lo·∫°i b·ªè comments trong JSON (// ho·∫∑c /* */)
        cleaned = re.sub(r'//.*?$', '', cleaned, flags=re.MULTILINE)
        cleaned = re.sub(r'/\*.*?\*/', '', cleaned, flags=re.DOTALL)
        
        # S·ª≠a trailing commas
        cleaned = re.sub(r',(\s*[}\]])', r'\1', cleaned)
        
        # S·ª≠a single quotes th√†nh double quotes (ch·ªâ cho keys v√† strings)
        # Pattern ph·ª©c t·∫°p h∆°n ƒë·ªÉ tr√°nh s·ª≠a nh·∫ßm apostrophes trong content
        cleaned = re.sub(r"'([^']*)':", r'"\1":', cleaned)  # Keys
        cleaned = re.sub(r":\s*'([^']*)'", r': "\1"', cleaned)  # String values
        
        # S·ª≠a c√°c k√Ω t·ª± escape ph·ªï bi·∫øn
        cleaned = cleaned.replace('\n', '\\n')
        cleaned = cleaned.replace('\t', '\\t')
        
        # Th·ª≠ parse tr·ª±c ti·∫øp
        return json.loads(cleaned)
        
    except json.JSONDecodeError as e:
        # N·∫øu v·∫´n l·ªói, th·ª≠ c√°c ph∆∞∆°ng ph√°p kh√°c
        try:
            # T√¨m v√† extract JSON object ƒë·∫ßu ti√™n
            json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                raise ValueError("Kh√¥ng t√¨m th·∫•y JSON object trong response")
                
        except Exception as e2:
            # Fallback: t·∫°o structure m·∫∑c ƒë·ªãnh v·ªõi th√¥ng tin t·ª´ response
            st.error(f"‚ùå Kh√¥ng th·ªÉ parse JSON. L·ªói: {str(e)}")
            st.error(f"V·ªã tr√≠ l·ªói: line {e.lineno}, column {e.colno}")
            
            # Hi·ªÉn th·ªã raw response ƒë·ªÉ debug
            with st.expander("üêõ Raw LLM Response (ƒë·ªÉ debug)", expanded=False):
                st.text(raw_response)
                st.text("=" * 50)
                st.text("Cleaned response:")
                st.text(cleaned)
            
            # Tr·∫£ v·ªÅ structure m·∫∑c ƒë·ªãnh
            return create_fallback_eda_structure(raw_response)

def create_fallback_eda_structure(raw_response):
    """
    T·∫°o structure EDA m·∫∑c ƒë·ªãnh khi kh√¥ng parse ƒë∆∞·ª£c JSON
    """
    return {
        "introduction": f"**Ph√¢n t√≠ch EDA t·ª± ƒë·ªông**\n\nƒê√£ ph√°t hi·ªán l·ªói khi t·∫°o b√°o c√°o EDA t·ª± ƒë·ªông. D∆∞·ªõi ƒë√¢y l√† th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu:\n\n{raw_response[:500]}...",
        "data_quality": "**ƒê√°nh gi√° Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu**\n\nVui l√≤ng ki·ªÉm tra th·ªß c√¥ng ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu.",
        "univariate": [
            {
                "insight": "Ph√¢n t√≠ch ƒë∆°n bi·∫øn c·∫ßn ƒë∆∞·ª£c th·ª±c hi·ªán th·ªß c√¥ng do l·ªói t·ª± ƒë·ªông.",
                "code": "# Ph√¢n t√≠ch th·ªß c√¥ng\nprint('Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu th·ªß c√¥ng')",
                "insight_after_chart": "C·∫ßn ph√¢n t√≠ch th·ªß c√¥ng."
            }
        ],
        "correlation": {
            "insight": "Ph√¢n t√≠ch t∆∞∆°ng quan c·∫ßn ƒë∆∞·ª£c th·ª±c hi·ªán th·ªß c√¥ng.",
            "code": "# Ph√¢n t√≠ch t∆∞∆°ng quan th·ªß c√¥ng\nprint('Vui l√≤ng t·∫°o correlation matrix th·ªß c√¥ng')",
            "insight_after_chart": "C·∫ßn ph√¢n t√≠ch t∆∞∆°ng quan th·ªß c√¥ng."
        },
        "insights": ["C·∫ßn ph√¢n t√≠ch th·ªß c√¥ng do l·ªói t·ª± ƒë·ªông"],
        "recommendations": ["Ki·ªÉm tra l·∫°i d·ªØ li·ªáu v√† prompt", "Th·ª≠ ch·∫°y l·∫°i b√°o c√°o EDA"]
    }

def generate_eda_report_with_llm(df):
    """
    T·∫°o b√°o c√°o EDA v·ªõi error handling m·∫°nh m·∫Ω
    """
    prompt = f"""
B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch d·ªØ li·ªáu chuy√™n nghi·ªáp. Ph√¢n t√≠ch b·ªô d·ªØ li·ªáu v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON h·ª£p l·ªá CH√çNH X√ÅC.

QUAN TR·ªåNG: Tr·∫£ v·ªÅ CH√çNH X√ÅC JSON h·ª£p l·ªá, kh√¥ng c√≥ markdown, kh√¥ng c√≥ comments, kh√¥ng c√≥ trailing commas.

C·∫•u tr√∫c JSON b·∫Øt bu·ªôc:
{{
  "introduction": "string",
  "data_quality": "string", 
  "univariate": [
    {{
      "insight": "string",
      "code": "string",
      "insight_after_chart": "string"
    }}
  ],
  "correlation": {{
    "insight": "string",
    "code": "string", 
    "insight_after_chart": "string"
  }},
  "insights": ["string1", "string2"],
  "recommendations": ["string1", "string2"]
}}

Metadata b·ªô d·ªØ li·ªáu:
- Shape: {df.shape}
- Columns: {list(df.columns)}
- Data types: {df.dtypes.to_dict()}
- Missing values: {df.isnull().sum().to_dict()}
- Numeric columns: {df.select_dtypes(include=['number']).columns.tolist()}

T·∫°o ph√¢n t√≠ch EDA chuy√™n nghi·ªáp. ƒê·∫£m b·∫£o JSON h·ª£p l·ªá 100%.
"""

    try:
        # G·ªçi LLM v·ªõi error handling
        response = llm.invoke([HumanMessage(content=prompt)])
        raw_content = response.content if hasattr(response, 'content') else str(response)
        
        # Parse JSON v·ªõi error handling m·∫°nh m·∫Ω
        return clean_and_fix_json(raw_content)
        
    except Exception as e:
        st.error(f"‚ùå L·ªói khi g·ªçi LLM: {str(e)}")
        
        # T·∫°o b√°o c√°o EDA c∆° b·∫£n thay th·∫ø
        return create_manual_eda_report(df)

def create_manual_eda_report(df):
    """
    T·∫°o b√°o c√°o EDA c∆° b·∫£n khi LLM fail
    """
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    missing_info = df.isnull().sum()
    
    univariate_analyses = []
    
    # T·∫°o ph√¢n t√≠ch cho m·ªôt v√†i c·ªôt ƒë·∫ßu ti√™n
    for col in df.columns:
        if col in numeric_cols and len(df[col] == 0) < 0.5 * len(df):
            code = f"""
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(df['{col}'], bins=30, kde=True)
plt.title('Ph√¢n ph·ªëi c·ªßa {col}')
plt.xlabel('{col}')
plt.ylabel('T·∫ßn su·∫•t')
plt.grid(True, alpha=0.3)
plt.tight_layout()
"""
        else:
            code = f"""
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
value_counts = df['{col}'].value_counts().head(10)
sns.barplot(x=value_counts.values, y=value_counts.index)
plt.title('Top 10 gi√° tr·ªã c·ªßa {col}')
plt.xlabel('S·ªë l∆∞·ª£ng')
plt.tight_layout()
"""
        
        univariate_analyses.append({
            "insight": f"Ph√¢n t√≠ch c·ªôt {col} - lo·∫°i {'s·ªë' if col in numeric_cols else 'ph√¢n lo·∫°i'}",
            "code": code,
            "insight_after_chart": f"C·∫ßn xem x√©t ph√¢n ph·ªëi v√† patterns c·ªßa {col}"
        })
    
    return {
        "introduction": f"""
## üìä Gi·ªõi thi·ªáu B·ªô d·ªØ li·ªáu

B·ªô d·ªØ li·ªáu n√†y c√≥ **{df.shape[0]:,} h√†ng** v√† **{df.shape[1]} c·ªôt**.

**Ph√¢n lo·∫°i c·ªôt:**
- C·ªôt s·ªë: {len(numeric_cols)} ({', '.join(numeric_cols)})
- C·ªôt ph√¢n lo·∫°i: {len(categorical_cols)} ({', '.join(categorical_cols)})

**T·ªïng quan nhanh:**
- T·ªïng s·ªë √¥ d·ªØ li·ªáu: {df.shape[0] * df.shape[1]:,}
- √î tr·ªëng: {df.isnull().sum().sum():,}
- T·ªâ l·ªá ho√†n thi·ªán: {((df.shape[0] * df.shape[1] - df.isnull().sum().sum()) / (df.shape[0] * df.shape[1]) * 100):.1f}%
""",
        "data_quality": f"""
## üßπ ƒê√°nh gi√° Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu

**Gi√° tr·ªã thi·∫øu theo c·ªôt:**
{chr(10).join([f"- {col}: {count} ({count/len(df)*100:.1f}%)" for col, count in missing_info[missing_info > 0].items()][:10])}

**ƒê√°nh gi√° t·ªïng quan:**
- Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu: {'T·ªët' if df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) < 0.05 else 'C·∫ßn c·∫£i thi·ªán'}
- C√°c c·ªôt c√≥ v·∫•n ƒë·ªÅ: {len(missing_info[missing_info > df.shape[0] * 0.1])} c·ªôt c√≥ >10% d·ªØ li·ªáu thi·∫øu
""",
        "univariate": univariate_analyses,
        "correlation": {
            "insight": f"Ph√¢n t√≠ch t∆∞∆°ng quan gi·ªØa {len(numeric_cols)} bi·∫øn s·ªë trong b·ªô d·ªØ li·ªáu.",
            "code": f"""
import matplotlib.pyplot as plt
import seaborn as sns

numeric_cols = {numeric_cols}
if len(numeric_cols) > 1:
    plt.figure(figsize=(12, 8))
    correlation_matrix = df[numeric_cols].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, cbar_kws={{'shrink': 0.8}})
    plt.title('Ma tr·∫≠n T∆∞∆°ng quan')
    plt.tight_layout()
else:
    print('C·∫ßn √≠t nh·∫•t 2 c·ªôt s·ªë ƒë·ªÉ t·∫°o ma tr·∫≠n t∆∞∆°ng quan')
""",
            "insight_after_chart": "Ma tr·∫≠n t∆∞∆°ng quan gi√∫p hi·ªÉu m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn s·ªë. C·∫ßn ch√∫ √Ω c√°c c·∫∑p bi·∫øn c√≥ t∆∞∆°ng quan m·∫°nh (>0.7 ho·∫∑c <-0.7)."
        },
        "insights": [
            f"B·ªô d·ªØ li·ªáu c√≥ k√≠ch th∆∞·ªõc v·ª´a ph·∫£i v·ªõi {df.shape[0]:,} quan s√°t",
            f"C√≥ {len(numeric_cols)} bi·∫øn s·ªë v√† {len(categorical_cols)} bi·∫øn ph√¢n lo·∫°i",
            f"T·ªâ l·ªá d·ªØ li·ªáu thi·∫øu l√† {df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100:.1f}%",
            "C·∫ßn ki·ªÉm tra th√™m v·ªÅ outliers v√† data distribution"
        ],
        "recommendations": [
            "X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu tr∆∞·ªõc khi ph√¢n t√≠ch s√¢u",
            "Ki·ªÉm tra v√† x·ª≠ l√Ω outliers trong c√°c bi·∫øn s·ªë", 
            "Th·ª±c hi·ªán feature engineering n·∫øu c·∫ßn",
            "Xem x√©t normalizing/scaling cho machine learning"
        ]
    }

def generate_final_summary_prompt(sections):
    return textwrap.dedent("""
        B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch d·ªØ li·ªáu c·∫•p cao ƒë∆∞·ª£c giao nhi·ªám v·ª• vi·∫øt m·ªôt b√°o c√°o EDA cu·ªëi c√πng chi ti·∫øt, chuy√™n nghi·ªáp cho m·ªôt b·ªô d·ªØ li·ªáu.
        B√°o c√°o c·ªßa b·∫°n s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã tr·ª±c ti·∫øp cho c√°c b√™n li√™n quan (v√≠ d·ª•: qu·∫£n tr·ªã tr∆∞·ªùng h·ªçc, nh√≥m khoa h·ªçc d·ªØ li·ªáu) v√¨ v·∫≠y n√≥ ph·∫£i to√†n di·ªán, s√¢u s·∫Øc v√† ƒë∆∞·ª£c vi·∫øt b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n tr√¥i ch·∫£y.

        C·∫•u tr√∫c b√°o c√°o trong markdown ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng t·ªët v·ªõi c√°c ph·∫ßn sau:

        ## üìò Gi·ªõi thi·ªáu
        T√≥m t·∫Øt n·ªôi dung b·ªô d·ªØ li·ªáu (s·ªë h√†ng, c·ªôt, lo·∫°i d·ªØ li·ªáu) v√† m·ª•c ƒë√≠ch c·ªßa n√≥. Bao g·ªìm b·∫£ng xem tr∆∞·ªõc.

        ## üßº Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu
        B√¨nh lu·∫≠n v·ªÅ gi√° tr·ªã thi·∫øu, b·∫£n ghi tr√πng l·∫∑p v√† ƒë·ªô tin c·∫≠y t·ªïng th·ªÉ. M√¥ t·∫£ b·∫•t k·ª≥ vi·ªác l√†m s·∫°ch d·ªØ li·ªáu n√†o c·∫ßn thi·∫øt ho·∫∑c ƒë√£ ƒë∆∞·ª£c th·ª±c hi·ªán.

        ## üîç Ph√¢n t√≠ch ƒê∆°n bi·∫øn
        T√≥m t·∫Øt c√°c m√¥ h√¨nh ch√≠nh ƒë∆∞·ª£c t√¨m th·∫•y trong c√°c c·ªôt ri√™ng l·∫ª, ƒë·∫∑c bi·ªát l√† c√°c c·ªôt s·ªë. ƒê·ªÅ c·∫≠p ƒë·∫øn ph√¢n ph·ªëi, gi√° tr·ªã ph·ªï bi·∫øn v√† gi√° tr·ªã ngo·∫°i l·ªá.
        Bao g·ªìm tham chi·∫øu ƒë·∫øn c√°c bi·ªÉu ƒë·ªì nh∆∞ bi·ªÉu ƒë·ªì t·∫ßn su·∫•t ho·∫∑c bi·ªÉu ƒë·ªì c·ªôt, v√† ƒë·∫∑t m·ªói bi·ªÉu ƒë·ªì ngay sau ƒëi·ªÉm li√™n quan c·ªßa n√≥. ƒê·∫£m b·∫£o th√¥ng tin chi ti·∫øt v√† bi·ªÉu ƒë·ªì li√™n quan xu·∫•t hi·ªán c√πng nhau trong k·∫øt xu·∫•t.

        ## üìä Th√¥ng tin T∆∞∆°ng quan
        M√¥ t·∫£ c√°c m·ªëi quan h·ªá ch√≠nh ƒë∆∞·ª£c kh√°m ph√° gi·ªØa c√°c c·∫∑p bi·∫øn. Gi·∫£i th√≠ch b·∫£n ƒë·ªì nhi·ªát v√† ch·ªâ ra c√°c t∆∞∆°ng quan m·∫°nh/y·∫øu. Cung c·∫•p √Ω nghƒ©a th·ª±c t·∫ø. Hi·ªÉn th·ªã b·∫£n ƒë·ªì nhi·ªát t∆∞∆°ng quan g·∫ßn m√¥ t·∫£.

        ## üí° Th√¥ng tin Cu·ªëi c√πng & Khuy·∫øn ngh·ªã
        T√≥m t·∫Øt k·∫øt lu·∫≠n c·ªßa b·∫°n v·ªÅ d·ªØ li·ªáu.
        ƒê∆∞a ra c√°c khuy·∫øn ngh·ªã th·ª±c t·∫ø (v√≠ d·ª•: c·∫£i thi·ªán d·ªØ li·ªáu, lƒ©nh v·ª±c t·∫≠p trung, ƒë·ªÅ xu·∫•t ch√≠nh s√°ch).

        Ch·ªâ s·ª≠ d·ª•ng markdown. Kh√¥ng c√≥ danh s√°ch d·∫•u ƒë·∫ßu d√≤ng tr·ª´ khi t√≥m t·∫Øt c√°c h√†nh ƒë·ªông cu·ªëi c√πng.
        ƒê·ªô d√†i: kho·∫£ng 600-800 t·ª´.
        T√¥ng ƒëi·ªáu: ph√¢n t√≠ch, c√≥ c·∫•u tr√∫c, h·ªØu √≠ch cho c√°c b√™n li√™n quan.
    """) + f"""

B·ªëi c·∫£nh:
- Gi·ªõi thi·ªáu: {sections['introduction']}
- Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu: {sections['data_quality']}
- ƒê∆°n bi·∫øn: {[b['insight_after_chart'] for b in sections['univariate'] if 'insight_after_chart' in b]}
- T∆∞∆°ng quan: {sections['correlation']['insight_after_chart']}
- Th√¥ng tin Ch√≠nh: {sections['insights']}
- Khuy·∫øn ngh·ªã: {sections['recommendations']}
"""

init_db()

# Load all datasets
datasets = get_all_datasets()
if not datasets:
    st.warning("Vui l√≤ng t·∫£i l√™n m·ªôt b·ªô d·ªØ li·ªáu trong B·∫£ng ƒëi·ªÅu khi·ªÉn tr∆∞·ªõc.")
    st.stop()

# Dataset selection
dataset_options = {f"{d[0]} - {d[1]}": d for d in datasets}
selected = st.selectbox("Ch·ªçn b·ªô d·ªØ li·ªáu ƒë·ªÉ t·∫°o b√°o c√°o:", list(dataset_options.keys()))
dataset_id, name, rows, cols, uploaded, _ = dataset_options[selected]
file_path = os.path.join("data", "uploads", name)
df = safe_read_csv(file_path)

# Enhanced error handling cho vi·ªác t·∫°o b√°o c√°o
try:
    st.info("ü§ñ ƒêang t·∫°o b√°o c√°o EDA v·ªõi AI...")
    
    # Progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    status_text.text("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu...")
    progress_bar.progress(25)
    
    # Call LLM-generated EDA content v·ªõi error handling
    eda_sections = generate_eda_report_with_llm(df)
    
    status_text.text("ƒêang t·∫°o insights...")
    progress_bar.progress(75)
    
    status_text.text("Ho√†n th√†nh!")
    progress_bar.progress(100)
    
    # Clear progress indicators
    progress_bar.empty()
    status_text.empty()
    
    st.success("‚úÖ ƒê√£ t·∫°o b√°o c√°o EDA th√†nh c√¥ng!")
    
except Exception as e:
    st.error(f"‚ùå L·ªói khi t·∫°o b√°o c√°o EDA: {str(e)}")
    st.info("üîÑ ƒêang chuy·ªÉn sang ch·∫ø ƒë·ªô b√°o c√°o th·ªß c√¥ng...")
    
    # Fallback to manual report
    eda_sections = create_manual_eda_report(df)
    st.warning("‚ö†Ô∏è ƒê√£ t·∫°o b√°o c√°o c∆° b·∫£n. M·ªôt s·ªë t√≠nh nƒÉng AI c√≥ th·ªÉ kh√¥ng kh·∫£ d·ª•ng.")

# Call LLM-generated EDA content
tabs = st.tabs(["üìò Gi·ªõi thi·ªáu", "üßº Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu", "üîç ƒê∆°n bi·∫øn", "üìä T∆∞∆°ng quan", "üí° Th√¥ng tin", "üìÑ B√°o c√°o ƒê·∫ßy ƒë·ªß"])

# --- üìò Introduction ---
with tabs[0]:
    st.markdown(eda_sections['introduction'])
    st.subheader("üìå Xem tr∆∞·ªõc B·ªô d·ªØ li·ªáu")
    st.dataframe(df.head(10))

# --- üßº Data Quality ---
with tabs[1]:
    st.markdown(eda_sections['data_quality'])
    st.subheader("Gi√° tr·ªã Thi·∫øu")
    missing = df.isnull().sum()
    missing = missing[missing > 0]
    if not missing.empty:
        st.dataframe(missing)
    else:
        st.success("Kh√¥ng ph√°t hi·ªán gi√° tr·ªã thi·∫øu.")
    st.subheader("H√†ng Tr√πng l·∫∑p")
    st.write(f"S·ªë h√†ng tr√πng l·∫∑p: **{df.duplicated().sum()}**")

    # Detailed per-column analysis
    st.subheader("üîé Ph√¢n t√≠ch theo C·ªôt")
    for col in df.columns:
        st.markdown(f"### üìå `{col}`")
        col_data = df[col]
        st.write(f"- Ki·ªÉu d·ªØ li·ªáu: `{col_data.dtype}`")
        st.write(f"- Gi√° tr·ªã thi·∫øu: `{col_data.isnull().sum()}` ({col_data.isnull().mean():.2%})")

        if pd.api.types.is_numeric_dtype(col_data):
            desc = col_data.describe()
            st.dataframe(desc.to_frame())
            try:
                fig, ax = plt.subplots()
                sns.histplot(col_data.dropna(), kde=True, ax=ax)
                ax.set_title(f"Ph√¢n ph·ªëi c·ªßa {col}")
                st.pyplot(fig)
            except Exception as e:
                st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì: {e}")
        elif pd.api.types.is_categorical_dtype(col_data) or col_data.dtype == object:
            value_counts = col_data.value_counts().head(10)
            st.dataframe(value_counts.to_frame(name='S·ªë l∆∞·ª£ng'))
            try:
                fig, ax = plt.subplots()
                sns.countplot(y=col_data, order=value_counts.index, ax=ax)
                ax.set_title(f"Gi√° tr·ªã h√†ng ƒë·∫ßu trong {col}")
                st.pyplot(fig)
            except Exception as e:
                st.warning(f"Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì: {e}")

# --- üîç Univariate Analysis ---
with tabs[2]:
    for block in eda_sections['univariate']:
        st.markdown(block['insight'])
        st.code(block['code'], language='python')
        try:
            local_env = {"df": df, "plt": plt, "sns": sns}
            exec(block['code'], local_env)
            st.pyplot(plt.gcf())
            plt.clf()
            if 'insight_after_chart' in block:
                st.info(block['insight_after_chart'])
        except Exception as e:
            st.error(f"L·ªói khi hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}")

# --- üìä Correlation ---
with tabs[3]:
    st.markdown(eda_sections['correlation']['insight'])
    st.code(eda_sections['correlation']['code'], language='python')
    try:
        local_env = {"df": df, "plt": plt, "sns": sns}
        exec(eda_sections['correlation']['code'], local_env)
        st.pyplot(plt.gcf())
        plt.clf()
        if 'insight_after_chart' in eda_sections['correlation']:
            st.info(eda_sections['correlation']['insight_after_chart'])
    except Exception as e:
        st.error(f"L·ªói khi hi·ªÉn th·ªã b·∫£n ƒë·ªì nhi·ªát t∆∞∆°ng quan: {e}")

# --- üí° Insights ---
with tabs[4]:
    st.subheader("üîñ ƒêi·ªÉm ch√≠nh & Khuy·∫øn ngh·ªã")
    prompt_summary = f"""
        B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch d·ªØ li·ªáu chuy√™n nghi·ªáp. V·ªõi c√°c t√≥m t·∫Øt sau t·ª´ qu√° tr√¨nh EDA:

        1. Gi·ªõi thi·ªáu b·ªô d·ªØ li·ªáu:
        {eda_sections['introduction']}

        2. V·∫•n ƒë·ªÅ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu:
        {eda_sections['data_quality']}

        3. Th√¥ng tin ƒë∆°n bi·∫øn:
        {[b['insight_after_chart'] for b in eda_sections['univariate'] if 'insight_after_chart' in b]}

        4. Th√¥ng tin t∆∞∆°ng quan:
        {eda_sections['correlation']['insight_after_chart']}

        Vi·∫øt m·ªôt ƒëo·∫°n t√≥m t·∫Øt g·∫Øn k·∫øt (~200-300 t·ª´) m√†:
        - Gi·∫£i th√≠ch c√°c m√¥ h√¨nh ho·∫∑c v·∫•n ƒë·ªÅ trong b·ªô d·ªØ li·ªáu.
        - L√†m n·ªïi b·∫≠t c√°c m·ªëi quan h·ªá quan tr·ªçng.
        - ƒê·ªÅ c·∫≠p ƒë·∫øn nh·ªØng ph√°t hi·ªán b·∫•t ng·ªù.
        - ƒê·ªÅ xu·∫•t nh·ªØng th√¥ng tin c√≥ th·ªÉ h√†nh ƒë·ªông.

        K·∫øt th√∫c b·∫±ng m·ªôt danh s√°ch ng·∫Øn g·ªçn c√°c khuy·∫øn ngh·ªã ·ªü ƒë·ªãnh d·∫°ng d·∫•u ƒë·∫ßu d√≤ng.
        Tr·∫£ l·ªùi b·∫±ng markdown.
        """
    
    try:
        summary_response = llm.invoke([HumanMessage(content=prompt_summary)]).content
    except Exception as e:
        st.error(f"L·ªói t·∫°o summary: {e}")
        summary_response = """
## üìä T√≥m t·∫Øt Ph√¢n t√≠ch

D·ª±a tr√™n ph√¢n t√≠ch EDA, b·ªô d·ªØ li·ªáu n√†y cho th·∫•y c√°c ƒë·∫∑c ƒëi·ªÉm sau:

### ƒêi·ªÉm n·ªïi b·∫≠t:
- K√≠ch th∆∞·ªõc d·ªØ li·ªáu ph√π h·ª£p cho ph√¢n t√≠ch
- Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c c·∫£i thi·ªán
- C√≥ ti·ªÅm nƒÉng ph√°t hi·ªán insights quan tr·ªçng

### Khuy·∫øn ngh·ªã:
- X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu
- Ki·ªÉm tra outliers
- Th·ª±c hi·ªán feature engineering
- √Åp d·ª•ng c√°c ph∆∞∆°ng ph√°p ph√¢n t√≠ch n√¢ng cao
"""
    
    st.markdown(summary_response)

# --- üìÑ Full Report ---
with tabs[5]:
    st.markdown("## üìÑ T√≥m t·∫Øt B√°o c√°o Cu·ªëi c√πng")

    # Render introduction + preview
    st.markdown("### üìò Gi·ªõi thi·ªáu")
    st.markdown(eda_sections['introduction'])
    st.dataframe(df.head())

    # Data Quality
    st.markdown("### üßº Ch·∫•t l∆∞·ª£ng D·ªØ li·ªáu")
    st.markdown(eda_sections['data_quality'])

    # Univariate
    st.markdown("### üîç Ph√¢n t√≠ch ƒê∆°n bi·∫øn")
    for block in eda_sections['univariate']:
        st.markdown(f"- {block['insight']}")
        st.code(block['code'], language="python")
        try:
            local_env = {"df": df, "plt": plt, "sns": sns}
            exec(block['code'], local_env)
            st.pyplot(plt.gcf())
            plt.clf()
            if 'insight_after_chart' in block:
                st.markdown(f"_{block['insight_after_chart']}_")
        except Exception as e:
            st.error(f"L·ªói: {e}")

    # Correlation
    st.markdown("### üìä Th√¥ng tin T∆∞∆°ng quan")
    st.markdown(eda_sections['correlation']['insight'])
    st.code(eda_sections['correlation']['code'], language="python")
    try:
        local_env = {"df": df, "plt": plt, "sns": sns}
        exec(eda_sections['correlation']['code'], local_env)
        st.pyplot(plt.gcf())
        plt.clf()
        st.markdown(f"_{eda_sections['correlation']['insight_after_chart']}_")
    except Exception as e:
        st.error(f"L·ªói b·∫£n ƒë·ªì nhi·ªát: {e}")

    # Final Summary from tab 4
    st.markdown("### üí° Th√¥ng tin Cu·ªëi c√πng & Khuy·∫øn ngh·ªã")
    st.markdown(summary_response)

    # Export PDF
    try:
        pdf_bytes = export_eda_report_to_pdf(eda_sections, df, summary_response, dataset_name=name)
        st.download_button("üìÑ T·∫£i xu·ªëng B√°o c√°o PDF", pdf_bytes, file_name=f"EDA_Report_{name}.pdf", mime="application/pdf")
    except Exception as e:
        st.error(f"L·ªói xu·∫•t PDF: {e}")
        st.info("Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá h·ªó tr·ª£")